from .generator import Generator

class BrokerControllerGenerator(Generator):
    def __init__(self, base):
        super().__init__(base)

    def generate_c3plusplus(self, environment: dict):
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_TYPE"] = "http"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_ENABLED"] = "true"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_METRICS_INCLUDE"] = \
        ("io.confluent.kafka.server.request.(?!.*delta).*|"
         "io.confluent.kafka.server.server.broker.state|"
         "io.confluent.kafka.server.replica.manager.leader.count|"
         "io.confluent.kafka.server.request.queue.size|"
         "io.confluent.kafka.server.broker.topic.failed.produce.requests.rate.1.min|"
         "io.confluent.kafka.server.tier.archiver.total.lag|"
         "io.confluent.kafka.server.request.total.time.ms.p99|"
         "io.confluent.kafka.server.broker.topic.failed.fetch.requests.rate.1.min|"
         "io.confluent.kafka.server.broker.topic.total.fetch.requests.rate.1.min|"
         "io.confluent.kafka.server.partition.caught.up.replicas.count|"
         "io.confluent.kafka.server.partition.observer.replicas.count|"
         "io.confluent.kafka.server.tier.tasks.num.partitions.in.error|"
         "io.confluent.kafka.server.broker.topic.bytes.out.rate.1.min|"
         "io.confluent.kafka.server.request.total.time.ms.p95|"
         "io.confluent.kafka.server.controller.active.controller.count|"
         "io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.total|"
         "io.confluent.kafka.server.request.total.time.ms.p999|"
         "io.confluent.kafka.server.controller.active.broker.count|"
         "io.confluent.kafka.server.request.handler.pool.request.handler.avg.idle.percent.rate.1.min|"
         "io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.rate.1.min|"
         "io.confluent.kafka.server.controller.unclean.leader.elections.rate.1.min|"
         "io.confluent.kafka.server.replica.manager.partition.count|"
         "io.confluent.kafka.server.controller.unclean.leader.elections.total|"
         "io.confluent.kafka.server.partition.replicas.count|"
         "io.confluent.kafka.server.broker.topic.total.produce.requests.rate.1.min|"
         "io.confluent.kafka.server.controller.offline.partitions.count|"
         "io.confluent.kafka.server.socket.server.network.processor.avg.idle.percent|"
         "io.confluent.kafka.server.partition.under.replicated|"
         "io.confluent.kafka.server.log.log.start.offset|"
         "io.confluent.kafka.server.log.tier.size|"
         "io.confluent.kafka.server.log.size|"
         "io.confluent.kafka.server.tier.fetcher.bytes.fetched.total|"
         "io.confluent.kafka.server.request.total.time.ms.p50|"
         "io.confluent.kafka.server.tenant.consumer.lag.offsets|"
         "io.confluent.kafka.server.session.expire.listener.zookeeper.expires.rate.1.min|"
         "io.confluent.kafka.server.log.log.end.offset|"
         "io.confluent.kafka.server.broker.topic.bytes.in.rate.1.min|"
         "io.confluent.kafka.server.partition.under.min.isr|"
         "io.confluent.kafka.server.partition.in.sync.replicas.count|"
         "io.confluent.telemetry.http.exporter.batches.dropped|"
         "io.confluent.telemetry.http.exporter.items.total|"
         "io.confluent.telemetry.http.exporter.items.succeeded|"
         "io.confluent.telemetry.http.exporter.send.time.total.millis|"
         "io.confluent.kafka.server.controller.leader.election.rate.(?!.*delta).*|"
         "io.confluent.telemetry.http.exporter.batches.failed")
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_BASE_URL"] = "http://prometheus:9090/api/v1/otlp"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_COMPRESSION"] = "gzip"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_KEY"] = "dummy"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_SECRET"] = "dummy"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_PENDING_BATCHES_MAX"] = "80"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_BATCH_ITEMS_MAX"] = "4000"
        environment["KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_INFLIGHT_SUBMISSIONS_MAX"] = "10"
        environment["KAFKA_CONFLUENT_TELEMETRY_METRICS_COLLECTOR_INTERVAL_MS"] = "60000"
        environment["KAFKA_CONFLUENT_TELEMETRY_REMOTECONFIG_CONFLUENT_ENABLED"] = "false"
